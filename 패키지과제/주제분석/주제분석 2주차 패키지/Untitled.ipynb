{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 분할\n",
    "## 1.1 데이터 불러오기\n",
    "trian.csv와 test.csv를 불러오세요.\n",
    "\n",
    "- train은 transaction_year가 5 미만인 경우,\n",
    "- test는 transaction_year가 5인 경우입니다. 알아두시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dong</th>\n",
       "      <th>apt</th>\n",
       "      <th>exclusive_use_area</th>\n",
       "      <th>floor</th>\n",
       "      <th>price</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>until_trans</th>\n",
       "      <th>sin_date</th>\n",
       "      <th>cos_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>사직동</td>\n",
       "      <td>광화문풍림스페이스본(9-0)</td>\n",
       "      <td>95.88</td>\n",
       "      <td>6</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>사직동</td>\n",
       "      <td>광화문풍림스페이스본(9-0)</td>\n",
       "      <td>108.55</td>\n",
       "      <td>11</td>\n",
       "      <td>100500</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사직동</td>\n",
       "      <td>광화문풍림스페이스본(9-0)</td>\n",
       "      <td>94.51</td>\n",
       "      <td>1</td>\n",
       "      <td>65800</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수송동</td>\n",
       "      <td>로얄팰리스스위트</td>\n",
       "      <td>42.87</td>\n",
       "      <td>8</td>\n",
       "      <td>30500</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수송동</td>\n",
       "      <td>로얄팰리스스위트</td>\n",
       "      <td>39.67</td>\n",
       "      <td>15</td>\n",
       "      <td>30500</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.061617e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dong              apt  exclusive_use_area  floor   price  transaction_year  \\\n",
       "0  사직동  광화문풍림스페이스본(9-0)               95.88      6   70000                 0   \n",
       "1  사직동  광화문풍림스페이스본(9-0)              108.55     11  100500                 0   \n",
       "2  사직동  광화문풍림스페이스본(9-0)               94.51      1   65800                 0   \n",
       "3  수송동         로얄팰리스스위트               42.87      8   30500                 0   \n",
       "4  수송동         로얄팰리스스위트               39.67     15   30500                 0   \n",
       "\n",
       "   until_trans      sin_date      cos_date  \n",
       "0            5 -1.000000e+00 -1.836970e-16  \n",
       "1            5 -2.449294e-16  1.000000e+00  \n",
       "2            5 -2.449294e-16  1.000000e+00  \n",
       "3            8 -1.000000e+00 -1.836970e-16  \n",
       "4            8  1.000000e+00  3.061617e-16  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 단위 수정\n",
    "x와 y도 분리해두세요.\n",
    "- train에만 일단 적용해주세요. 우린 아직 test데이터를 보지 못했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dong</th>\n",
       "      <th>apt</th>\n",
       "      <th>exclusive_use_area</th>\n",
       "      <th>floor</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>until_trans</th>\n",
       "      <th>sin_date</th>\n",
       "      <th>cos_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>사직동</td>\n",
       "      <td>광화문풍림스페이스본(9-0)</td>\n",
       "      <td>95.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>사직동</td>\n",
       "      <td>광화문풍림스페이스본(9-0)</td>\n",
       "      <td>108.55</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사직동</td>\n",
       "      <td>광화문풍림스페이스본(9-0)</td>\n",
       "      <td>94.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수송동</td>\n",
       "      <td>로얄팰리스스위트</td>\n",
       "      <td>42.87</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수송동</td>\n",
       "      <td>로얄팰리스스위트</td>\n",
       "      <td>39.67</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.061617e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422159</th>\n",
       "      <td>강일동</td>\n",
       "      <td>강일리버파크2단지</td>\n",
       "      <td>84.74</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-2.204364e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422160</th>\n",
       "      <td>강일동</td>\n",
       "      <td>고덕리엔파크2단지</td>\n",
       "      <td>59.83</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.892397e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422161</th>\n",
       "      <td>강일동</td>\n",
       "      <td>강일리버파크5단지</td>\n",
       "      <td>59.87</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.892397e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422162</th>\n",
       "      <td>강일동</td>\n",
       "      <td>강일리버파크4단지</td>\n",
       "      <td>84.83</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5.879543e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422163</th>\n",
       "      <td>강일동</td>\n",
       "      <td>강일리버파크9단지</td>\n",
       "      <td>84.74</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5.879543e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422164 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dong              apt  exclusive_use_area  floor  transaction_year  \\\n",
       "0       사직동  광화문풍림스페이스본(9-0)               95.88      6                 0   \n",
       "1       사직동  광화문풍림스페이스본(9-0)              108.55     11                 0   \n",
       "2       사직동  광화문풍림스페이스본(9-0)               94.51      1                 0   \n",
       "3       수송동         로얄팰리스스위트               42.87      8                 0   \n",
       "4       수송동         로얄팰리스스위트               39.67     15                 0   \n",
       "...     ...              ...                 ...    ...               ...   \n",
       "422159  강일동        강일리버파크2단지               84.74      6                 4   \n",
       "422160  강일동        고덕리엔파크2단지               59.83      7                 4   \n",
       "422161  강일동        강일리버파크5단지               59.87      1                 4   \n",
       "422162  강일동        강일리버파크4단지               84.83      9                 4   \n",
       "422163  강일동        강일리버파크9단지               84.74     13                 4   \n",
       "\n",
       "        until_trans      sin_date      cos_date  \n",
       "0                 5 -1.000000e+00 -1.836970e-16  \n",
       "1                 5 -2.449294e-16  1.000000e+00  \n",
       "2                 5 -2.449294e-16  1.000000e+00  \n",
       "3                 8 -1.000000e+00 -1.836970e-16  \n",
       "4                 8  1.000000e+00  3.061617e-16  \n",
       "...             ...           ...           ...  \n",
       "422159            8 -2.204364e-15  1.000000e+00  \n",
       "422160            6  1.000000e+00  4.892397e-16  \n",
       "422161            8  1.000000e+00  4.892397e-16  \n",
       "422162            8  5.879543e-15 -1.000000e+00  \n",
       "422163            8  5.879543e-15 -1.000000e+00  \n",
       "\n",
       "[422164 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=train[['price']]\n",
    "y\n",
    "X=train.drop(['price'],axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 validation set 분할 - 첫번째\n",
    "- 사이킷런의 train_test_split을 통해 train데이터를 8:2로 validation set을 만들어주세요.\n",
    "- 즉 train중에서 train/val이 있고, test set이 따로 존재합니다.\n",
    "- test set은 전처리 과정에서 절대 사용되지 않을 예정입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid=train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 질문\n",
    "- 이렇게 데이터를 나눌 경우 어떤 문제가 발생할 수 있을까요?\n",
    "- 힌트) 현재 데이터는 관측된 시간이 존재합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "답: train 데이터가 특정 시간에 몰릴 경우, 즉 각 특징들의 알맞은 비율만큼 푸풀되지 않는 경우 예측에 문제가 발생할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 validation set 분할 - 두번째\n",
    "transaction_year == 4인 행을 validation으로 지정해서 분할하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dong</th>\n",
       "      <th>apt</th>\n",
       "      <th>exclusive_use_area</th>\n",
       "      <th>floor</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>until_trans</th>\n",
       "      <th>sin_date</th>\n",
       "      <th>cos_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401216</th>\n",
       "      <td>천호동</td>\n",
       "      <td>동아하이빌</td>\n",
       "      <td>114.980</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-3.184701e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179939</th>\n",
       "      <td>홍은동</td>\n",
       "      <td>유원</td>\n",
       "      <td>54.540</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>-1.224647e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231270</th>\n",
       "      <td>방화동</td>\n",
       "      <td>청솔</td>\n",
       "      <td>59.040</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-6.861117e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113810</th>\n",
       "      <td>쌍문동</td>\n",
       "      <td>한양2</td>\n",
       "      <td>35.100</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1.102182e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120620</th>\n",
       "      <td>중계동</td>\n",
       "      <td>동진</td>\n",
       "      <td>47.610</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-6.861117e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>온수동</td>\n",
       "      <td>온수힐스테이트</td>\n",
       "      <td>59.960</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.347881e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365838</th>\n",
       "      <td>대치동</td>\n",
       "      <td>은마</td>\n",
       "      <td>84.430</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>-7.347881e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>월계동</td>\n",
       "      <td>삼창</td>\n",
       "      <td>77.840</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-3.184701e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>중계동</td>\n",
       "      <td>중계무지개</td>\n",
       "      <td>39.820</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>5.389684e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>월계동</td>\n",
       "      <td>롯데캐슬루나</td>\n",
       "      <td>84.985</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6.123234e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337731 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dong      apt  exclusive_use_area  floor  transaction_year  \\\n",
       "401216  천호동    동아하이빌             114.980     17                 0   \n",
       "179939  홍은동       유원              54.540      4                 3   \n",
       "231270  방화동       청솔              59.040      6                 2   \n",
       "113810  쌍문동      한양2              35.100      5                 4   \n",
       "120620  중계동       동진              47.610      3                 0   \n",
       "...     ...      ...                 ...    ...               ...   \n",
       "259178  온수동  온수힐스테이트              59.960      4                 3   \n",
       "365838  대치동       은마              84.430     11                 4   \n",
       "131932  월계동       삼창              77.840     11                 2   \n",
       "146867  중계동    중계무지개              39.820      4                 3   \n",
       "121958  월계동   롯데캐슬루나              84.985      9                 1   \n",
       "\n",
       "        until_trans      sin_date      cos_date  \n",
       "401216           13 -1.000000e+00 -3.184701e-15  \n",
       "179939           29 -1.224647e-15  1.000000e+00  \n",
       "231270           21  1.000000e+00 -6.861117e-15  \n",
       "113810           28  1.102182e-15 -1.000000e+00  \n",
       "120620           25  1.000000e+00 -6.861117e-15  \n",
       "...             ...           ...           ...  \n",
       "259178            6 -7.347881e-16  1.000000e+00  \n",
       "365838           37 -7.347881e-16  1.000000e+00  \n",
       "131932           31 -1.000000e+00 -3.184701e-15  \n",
       "146867           25  5.389684e-15 -1.000000e+00  \n",
       "121958            8  6.123234e-16 -1.000000e+00  \n",
       "\n",
       "[337731 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_four = train['transaction_year'] == 4\n",
    "validation=train[is_four]\n",
    "validation_y=validation[['price']]\n",
    "validation_X=validation.drop(['price'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "not_four=train['transaction_year'] != 4\n",
    "train=train[not_four]\n",
    "train_y=train[['price']]\n",
    "train_X=train.drop(['price'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 캣부스트 인코딩 전에\n",
    "일단 캣부스트 인코딩을 위해 다음을 설치하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Using cached category_encoders-2.2.2-py2.py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from category_encoders) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from category_encoders) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from category_encoders) (1.19.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from category_encoders) (0.12.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from category_encoders) (1.5.2)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2020.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 캣부스트 인코딩\n",
    "- 방금까지 trainset을 분할했죠? 그 분할된 것을 캣부스트 인코딩의 인자로 받을 겁니다.\n",
    "- train에서 분할된 train을 인코딩을 위한 학습으로 사용해서, 이를 validation_x에 적용합니다.\n",
    "- 해당 결과를 head()를 통해 보여주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and target\n",
    "#target = train[['grade']]\n",
    "#train = train.drop('grade', axis = 1)\n",
    "  \n",
    "# Define catboost encoder\n",
    "cbe_encoder = ce.cat_boost.CatBoostEncoder()\n",
    "  \n",
    "# Fit encoder and transform the features\n",
    "cbe_encoder.fit(train_X, train_y)\n",
    "val_cbe = cbe_encoder.transform(validation_X)\n",
    "\n",
    "#https://www.geeksforgeeks.org/categorical-encoding-with-catboost-encoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dong</th>\n",
       "      <th>apt</th>\n",
       "      <th>exclusive_use_area</th>\n",
       "      <th>floor</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>until_trans</th>\n",
       "      <th>sin_date</th>\n",
       "      <th>cos_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>107.91</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>151.81</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>94.51</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>94.28</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>103789.156533</td>\n",
       "      <td>107170.755379</td>\n",
       "      <td>145.96</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dong            apt  exclusive_use_area  floor  \\\n",
       "2451   89176.597368   86280.203194              107.91     14   \n",
       "2452   89176.597368   86280.203194              151.81     10   \n",
       "2453   89176.597368   86280.203194               94.51      2   \n",
       "2454   89176.597368   86280.203194               94.28     12   \n",
       "2455  103789.156533  107170.755379              145.96     13   \n",
       "\n",
       "      transaction_year  until_trans      sin_date      cos_date  \n",
       "2451                 4            9 -1.000000e+00 -1.836970e-16  \n",
       "2452                 4            9 -1.000000e+00 -1.836970e-16  \n",
       "2453                 4            9 -2.449294e-16  1.000000e+00  \n",
       "2454                 4            9 -2.449294e-16  1.000000e+00  \n",
       "2455                 4           13 -1.000000e+00 -1.836970e-16  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_cbe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cbe=cbe_encoder.transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 릿지 회귀 (Ridge Regression)\n",
    "성능이 좋다고 알려진 부스팅모델 두개 하려다가, 그냥 릿지로 선회했습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트의 정확도 : 0.86\n",
      "테스트 세트의 정확도 : 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge().fit(train_cbe, train_y)\n",
    "\n",
    "print(\"훈련 세트의 정확도 : {:.2f}\".format(ridge.score(train_cbe,train_y)))\n",
    "\n",
    "print(\"테스트 세트의 정확도 : {:.2f}\".format(ridge.score(val_cbe,validation_y)))\n",
    "#https://blog.naver.com/PostView.nhn?blogId=ssdyka&logNo=221231456916"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 상관계수 플랏\n",
    "- 캣부스트 인코딩을 시행한 튜닝을 위한 trainset에 대해 상관계수플랏을 그리세요.\n",
    "- 해석해주세요. 릿지 회귀가 잘 작동할까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dong</th>\n",
       "      <th>apt</th>\n",
       "      <th>exclusive_use_area</th>\n",
       "      <th>floor</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>until_trans</th>\n",
       "      <th>sin_date</th>\n",
       "      <th>cos_date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>95.88</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>108.55</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>94.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>65800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36772.527903</td>\n",
       "      <td>36772.527903</td>\n",
       "      <td>42.87</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>30500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36772.527903</td>\n",
       "      <td>36772.527903</td>\n",
       "      <td>39.67</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.061617e-16</td>\n",
       "      <td>30500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416312</th>\n",
       "      <td>41897.713781</td>\n",
       "      <td>43050.956617</td>\n",
       "      <td>84.74</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5.879543e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416313</th>\n",
       "      <td>41897.713781</td>\n",
       "      <td>41799.433128</td>\n",
       "      <td>84.53</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5.879543e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>44000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416314</th>\n",
       "      <td>41897.713781</td>\n",
       "      <td>38541.570789</td>\n",
       "      <td>84.83</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5.879543e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>47500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416315</th>\n",
       "      <td>41897.713781</td>\n",
       "      <td>43050.956617</td>\n",
       "      <td>84.53</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5.879543e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>45700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416316</th>\n",
       "      <td>41897.713781</td>\n",
       "      <td>38393.383949</td>\n",
       "      <td>84.53</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5.879543e-15</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>44000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312466 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dong           apt  exclusive_use_area  floor  \\\n",
       "0       89176.597368  86280.203194               95.88      6   \n",
       "1       89176.597368  86280.203194              108.55     11   \n",
       "2       89176.597368  86280.203194               94.51      1   \n",
       "3       36772.527903  36772.527903               42.87      8   \n",
       "4       36772.527903  36772.527903               39.67     15   \n",
       "...              ...           ...                 ...    ...   \n",
       "416312  41897.713781  43050.956617               84.74      9   \n",
       "416313  41897.713781  41799.433128               84.53      7   \n",
       "416314  41897.713781  38541.570789               84.83      6   \n",
       "416315  41897.713781  43050.956617               84.53     13   \n",
       "416316  41897.713781  38393.383949               84.53      8   \n",
       "\n",
       "        transaction_year  until_trans      sin_date      cos_date   price  \n",
       "0                      0            5 -1.000000e+00 -1.836970e-16   70000  \n",
       "1                      0            5 -2.449294e-16  1.000000e+00  100500  \n",
       "2                      0            5 -2.449294e-16  1.000000e+00   65800  \n",
       "3                      0            8 -1.000000e+00 -1.836970e-16   30500  \n",
       "4                      0            8  1.000000e+00  3.061617e-16   30500  \n",
       "...                  ...          ...           ...           ...     ...  \n",
       "416312                 3            7  5.879543e-15 -1.000000e+00   45500  \n",
       "416313                 3            7  5.879543e-15 -1.000000e+00   44000  \n",
       "416314                 3            7  5.879543e-15 -1.000000e+00   47500  \n",
       "416315                 3            7  5.879543e-15 -1.000000e+00   45700  \n",
       "416316                 3            7  5.879543e-15 -1.000000e+00   44000  \n",
       "\n",
       "[312466 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "train=pd.concat([train_cbe,train_y],axis=1)\n",
    "corr = train.corr()\n",
    "sns.heatmap(corr, cmap='viridis')\n",
    "\n",
    "plt.show()\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 해석과 무관하게 일단 릿지 튜닝\n",
    "- mse를 비교해서 튜닝을 진행하세요.\n",
    "- 릿지의 튜닝파라미터 알파는 0.00001, 0.0001, 0.001, 0.01, 0.1로 설정합니다.\n",
    "- 알파가 클수록 강한 페널티입니다.\n",
    "- 튜닝결과를 시각화해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11355.138932325644\n",
      "0.8648445823631539\n",
      "15377.977659081647\n",
      "0.816472384035736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score #https://www.pluralsight.com/guides/linear-lasso-ridge-regression-scikit-learn\n",
    "\n",
    "rr = Ridge(alpha=0.00001)       \n",
    "rr.fit(train_cbe, train_y) \n",
    "pred_train_rr= rr.predict(train_cbe)\n",
    "print(np.sqrt(mean_squared_error(train_y,pred_train_rr)))\n",
    "print(r2_score(train_y, pred_train_rr))\n",
    "\n",
    "pred_val_rr= rr.predict(val_cbe)\n",
    "print(np.sqrt(mean_squared_error(validation_y,pred_val_rr))) \n",
    "print(r2_score(validation_y, pred_val_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11355.138932325644\n",
      "0.8648445823631539\n",
      "15377.977659258408\n",
      "0.8164723840315169\n"
     ]
    }
   ],
   "source": [
    "rr = Ridge(alpha=0.0001)       \n",
    "rr.fit(train_cbe, train_y) \n",
    "pred_train_rr= rr.predict(train_cbe)\n",
    "print(np.sqrt(mean_squared_error(train_y,pred_train_rr)))\n",
    "print(r2_score(train_y, pred_train_rr))\n",
    "\n",
    "pred_val_rr= rr.predict(val_cbe)\n",
    "print(np.sqrt(mean_squared_error(validation_y,pred_val_rr))) \n",
    "print(r2_score(validation_y, pred_val_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11355.138932325644\n",
      "0.8648445823631539\n",
      "15377.977661026003\n",
      "0.8164723839893263\n"
     ]
    }
   ],
   "source": [
    "rr = Ridge(alpha=0.001)       \n",
    "rr.fit(train_cbe, train_y) \n",
    "pred_train_rr= rr.predict(train_cbe)\n",
    "print(np.sqrt(mean_squared_error(train_y,pred_train_rr)))\n",
    "print(r2_score(train_y, pred_train_rr))\n",
    "\n",
    "pred_val_rr= rr.predict(val_cbe)\n",
    "print(np.sqrt(mean_squared_error(validation_y,pred_val_rr))) \n",
    "print(r2_score(validation_y, pred_val_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11355.13893232564\n",
      "0.864844582363154\n",
      "15377.97767870193\n",
      "0.8164723835674216\n"
     ]
    }
   ],
   "source": [
    "rr = Ridge(alpha=0.01)       \n",
    "rr.fit(train_cbe, train_y) \n",
    "pred_train_rr= rr.predict(train_cbe)\n",
    "print(np.sqrt(mean_squared_error(train_y,pred_train_rr)))\n",
    "print(r2_score(train_y, pred_train_rr))\n",
    "\n",
    "pred_val_rr= rr.predict(val_cbe)\n",
    "print(np.sqrt(mean_squared_error(validation_y,pred_val_rr))) \n",
    "print(r2_score(validation_y, pred_val_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11355.138932325655\n",
      "0.8648445823631536\n",
      "15377.977855461197\n",
      "0.8164723793483744\n"
     ]
    }
   ],
   "source": [
    "rr = Ridge(alpha=0.1)       \n",
    "rr.fit(train_cbe, train_y) \n",
    "pred_train_rr= rr.predict(train_cbe)\n",
    "print(np.sqrt(mean_squared_error(train_y,pred_train_rr)))\n",
    "print(r2_score(train_y, pred_train_rr))\n",
    "\n",
    "pred_val_rr= rr.predict(val_cbe)\n",
    "print(np.sqrt(mean_squared_error(validation_y,pred_val_rr))) \n",
    "print(r2_score(validation_y, pred_val_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha=[0.00001,0.0001,0.001,0.01,0.1] #https://todayisbetterthanyesterday.tistory.com/14\n",
    "#alpha = np.logspace(-5,-1,5)\n",
    "#alpha\n",
    "# lambda값 지정\n",
    "# 0.001 <= lambda <= 10\n",
    "#data = pd.DataFrame()\n",
    "#acc_table = []\n",
    "\n",
    "#for i, a in enumerate(alpha):\n",
    "#    ridge = Ridge(alpha=a).fit(train_cbe, train_y)\n",
    "#    data.append(pd.Series(np.hstack([ridge.coef_])))\n",
    "#    pred_y = ridge.predict(vla_cbe) # full model\n",
    "#    pred_y = cut_off(pred_y, 0.5)\n",
    "#    cfmat = confusion_matrix(validation_y,pred_y)\n",
    "#    acc_table.append((acc(cfmat)))\n",
    "    \n",
    "    \n",
    "#df_ridge = pd.DataFrame(data,index = alpha).T\n",
    "#acc_table_ridge = pd.DataFrame(acc_table, index = alpha).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 튜닝결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 해석\n",
    "튜닝 결과에 대한 플랏을 보고 해석을 해주세요.\n",
    "\n",
    "튜닝이 잘되었나요?\n",
    "튜닝이 안되었다면 그 이유는 무엇인가요?\n",
    "\n",
    "https://stats.stackexchange.com/questions/81395/relationship-between-ridge-regression-and-pca-regression\n",
    "\n",
    "수식이 쉽진 않을텐데 그냥 슬쩍 보세요...ㅎㅎㅎ\n",
    "https://online.stat.psu.edu/stat508/lesson/5/5.1\n",
    "penn state자료는 맨 아래부분만 보면 됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 그냥 선형 모형으로!\n",
    "- 그냥 linear regression을 튜닝을 위한 trainset에 적합시키고, validation set에 대한 rmse를 계산하세요.\n",
    "\n",
    "- linear regression은 다른 튜닝 파라미터를 필요로하지 않습니다.\n",
    "- ridge와의 validation rmse를 비교했을 때, 어떤 모형을 쓰는 것이 나을지 말해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_errors: 15377.97765906307\n"
     ]
    }
   ],
   "source": [
    "line_fitter = LinearRegression()\n",
    "line_fitter.fit(train_cbe, train_y)\n",
    "y_predicted = line_fitter.predict(val_cbe)\n",
    "print('mean_squared_errors: {}'.format(np.sqrt(mean_squared_error(validation_y, y_predicted ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "답: linear이 나음 rmse가 작은 것이 좋음  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LightGBM\n",
    "강력하면서도 빠른 부스팅 모형인 LGBM에 대해 다룰 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\user\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (0.35.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\user\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (0.35.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "\n",
    "#!{sys.executable} -m pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 LightGBM 이해\n",
    "모형에 대해 아주 기본적인 이해는 필요하겠죠? LGBM의 특징/장점/문제점을 적어주세요.\n",
    "\n",
    "- 20-01 데마팀 클린업 3주차 혹은 또 다른 데마팀 클린업을 보셔도 괜찮습니다.\n",
    "- 구글링해도 잘 나옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특징: \n",
    "LightGBM의 리프 중심 트리 분할은 트리의 균형을 맞추지 않고 최대 손실 값(Max data loss)을 가지는 리프 노트를 지속적으로 분할하면서 트리의 깊이가 깊어지고 \"비대칭적인 트리\"가 생성된다. 최대 손실값을 가지는 리프 노드를 반복할수록 결국은 균형 트리의 분할 방식보다 예측 오류 손실을 최소화 할 수 있다.\n",
    "\n",
    "### 장점:\n",
    "- 학습하는데 걸리는 시간이 적다.\n",
    "- 메모리 사용량이 상대적으로 적은편이다.\n",
    "- 카테고리형 피처들의 자동 변환과 최적 분할\n",
    "\n",
    "### 단점: \n",
    "- 적은 데이터 세트의 적용을 할 경우 과적합 가능성이 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 LGBM 튜닝\n",
    "LGBM의 튜닝파라미터는 많습니다.\n",
    "- max_depth, learning_rate, lambda, min_child_samples 등 다양한데, 패키지에서는 learning rate만 튜닝하도록 하겠습니다.\n",
    "- [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.99] 이렇게 튜닝해주세요.\n",
    "- 부스팅에서는 일단 learning rate과 iteration의 trade off를 적절하게 고려해줘서 학습속도를 맞춰준다음, 세부적인 튜닝을 하는게 일반적입니다.\n",
    "- 더하고 싶으면 해서 더 좋은 성능을 내셔도 됩니다! 보통 enumerate를 통해 파라미터를 묶어줘서 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMModel,LGBMRegressor,LGBMClassifier\n",
    "# import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 312466, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 46056.618349\n",
      "mean_squared_errors: 10389.411606011838\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 312466, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 46056.618349\n",
      "mean_squared_errors: 9206.332029581423\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 312466, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 46056.618349\n",
      "mean_squared_errors: 8882.098842260984\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 312466, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 46056.618349\n",
      "mean_squared_errors: 8613.157765398855\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 312466, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 46056.618349\n",
      "mean_squared_errors: 8775.46913077823\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 312466, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 46056.618349\n",
      "mean_squared_errors: 9109.802807709111\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 881\n",
      "[LightGBM] [Info] Number of data points in the train set: 312466, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 46056.618349\n",
      "mean_squared_errors: 10036.81985447445\n"
     ]
    }
   ],
   "source": [
    "train_ds=lgb.Dataset(train_cbe,label=train_y)\n",
    "val_ds=lgb.Dataset(val_cbe,label=validation_y)\n",
    "rate= [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.99]\n",
    "for rate in rate:\n",
    "    params={'learning_rate':rate}\n",
    "    model=lgb.train(params,train_ds,1000,val_ds)\n",
    "    y_pred=model.predict(val_cbe)\n",
    "    print('mean_squared_errors: {}'.format(np.sqrt(mean_squared_error(validation_y, y_pred ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. test set\n",
    "## 4.1 test set 불러오기\n",
    "test set을 불러오고, X와 y를 분리하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\")\n",
    "train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y=test[['price']]\n",
    "test_X=test.drop(['price'],axis=1)\n",
    "train_y=train[['price']]\n",
    "train_X=train.drop(['price'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 캣부스트 인코딩\n",
    "- 전체 train set에 대해 캣부스트 인코딩을 시행해주세요.\n",
    "- 인자에는 train_x/train_y/test_x가 들어갈겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define catboost encoder\n",
    "cbe_encoder = ce.cat_boost.CatBoostEncoder()\n",
    "  \n",
    "# Fit encoder and transform the features\n",
    "cbe_encoder.fit(train_X, train_y)\n",
    "test_cbe = cbe_encoder.transform(test_X)\n",
    "train_cbe=cbe_encoder.transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 최적의 파라미터 적합\n",
    "2와 3의 결과에서 최적의 파라미터(모델)을 전체 trainset에 대해 적합하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_errors: 17721.88060515686\n"
     ]
    }
   ],
   "source": [
    "line_fitter = LinearRegression()\n",
    "line_fitter.fit(train_cbe, train_y)\n",
    "y_predicted = line_fitter.predict(test_cbe)\n",
    "print('mean_squared_errors: {}'.format(np.sqrt(mean_squared_error(test_y, y_predicted ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 422164, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 48041.092876\n",
      "mean_squared_errors: 12731.13273779304\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 422164, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 48041.092876\n",
      "mean_squared_errors: 11485.588067798715\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 422164, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 48041.092876\n",
      "mean_squared_errors: 11057.470960881203\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 422164, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 48041.092876\n",
      "mean_squared_errors: 10986.411265888806\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 422164, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 48041.092876\n",
      "mean_squared_errors: 11168.444477662648\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 422164, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 48041.092876\n",
      "mean_squared_errors: 11473.592263303757\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 422164, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 48041.092876\n",
      "mean_squared_errors: 12082.079118864973\n"
     ]
    }
   ],
   "source": [
    "train_ds=lgb.Dataset(train_cbe,label=train_y)\n",
    "test_ds=lgb.Dataset(test_cbe,label=test_y)\n",
    "rate= [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.99]\n",
    "for rate in rate:\n",
    "    params={'learning_rate':rate}\n",
    "    model=lgb.train(params,train_ds,1000,test_ds)\n",
    "    y_pred=model.predict(test_cbe)\n",
    "    print('mean_squared_errors: {}'.format(np.sqrt(mean_squared_error(test_y, y_pred ))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 test set에 대해 평가\n",
    "두 모델을 test set에 대해 평가해서 비교하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse가 LGBM learnigrate가 0.3일때 제일 작음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
